import os
import cv2
import random
import shutil
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
import torch.nn as nn
import torch.optim as optim
import torch
from PIL import Image
import zipfile

# Google Drive에서 dfdc_train_part_00 파일 경로
zip_file_path = '/content/drive/MyDrive/dfdc_train_part_00.zip'

# 압축 해제할 폴더 경로
extracted_folder = 'deepfake_dataset'

# 압축 해제
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extracted_folder)

# 압축 해제된 폴더 경로를 data_folder에 할당
data_folder = extracted_folder

# ------------------------------
# 1. 설정
# ------------------------------
# 데이터 준비 및 학습을 위한 주요 설정 값들
data_folder = 'deepfake_dataset'  # 압축 해제된 데이터셋 폴더 경로
train_folder = 'dataset/train'   # 학습 데이터가 저장될 폴더
val_folder = 'dataset/val'       # 검증 데이터가 저장될 폴더
frame_count = 10                 # 각 영상에서 추출할 프레임 개수
split_ratio = 0.8                # 학습 데이터와 검증 데이터의 분할 비율 (80:20)
image_size = (64, 64)            # 추출된 이미지의 크기 (리사이즈)
batch_size = 16                  # 학습 시 한 번에 처리할 데이터 샘플 크기
num_epochs = 10                  # 학습 반복 횟수 (에폭)
learning_rate = 0.001            # 학습률

# ------------------------------
# 2. 데이터 준비 함수
# ------------------------------
def extract_frames_from_videos(data_folder, output_folder, frame_count, image_size):
    """
    각 클래스 폴더 ('real', 'fake')에서 영상을 읽어 일정 개수의 프레임을 추출하고 저장합니다.
    :param data_folder: 영상 데이터가 있는 폴더 경로
    :param output_folder: 추출된 프레임이 저장될 폴더 경로
    :param frame_count: 각 영상에서 추출할 프레임 개수
    :param image_size: 추출된 프레임의 리사이즈 크기
    """
    os.makedirs(output_folder, exist_ok=True)  # 출력 폴더 생성
    for class_name in os.listdir(data_folder):  # 각 클래스 ('real', 'fake') 순회
        class_path = os.path.join(data_folder, class_name)  # 각 클래스 폴더 경로
        output_class_folder = os.path.join(output_folder, class_name)  # 출력 폴더 경로
        os.makedirs(output_class_folder, exist_ok=True)  # 클래스별 폴더 생성

        for video_file in os.listdir(class_path):  # 클래스 내 영상 파일 순회
            video_path = os.path.join(class_path, video_file)  # 영상 파일 경로
            cap = cv2.VideoCapture(video_path)  # OpenCV로 영상 파일 열기
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # 영상의 총 프레임 수
            interval = max(total_frames // frame_count, 1)  # 프레임 간격 계산 (최소 1)

            frame_number = 0
            saved_frames = 0
            video_name = os.path.splitext(video_file)[0]  # 영상 파일 이름(확장자 제외)

            while cap.isOpened() and saved_frames < frame_count:  # 영상 읽기 루프
                ret, frame = cap.read()
                if not ret:
                    break  # 영상 끝에 도달하면 종료
                if frame_number % interval == 0:  # 간격에 따라 프레임 추출
                    frame_filename = os.path.join(output_class_folder, f"{video_name}_frame_{saved_frames}.jpg")
                    resized_frame = cv2.resize(frame, image_size)  # 프레임 리사이즈
                    cv2.imwrite(frame_filename, resized_frame)  # 프레임 저장
                    saved_frames += 1
                frame_number += 1
            cap.release()  # 영상 파일 닫기


def split_dataset(input_folder, train_folder, val_folder, split_ratio):
    """
    데이터셋을 학습용 데이터와 검증용 데이터로 나눕니다.
    :param input_folder: 입력 데이터 폴더 (프레임 저장 위치)
    :param train_folder: 학습 데이터가 저장될 폴더
    :param val_folder: 검증 데이터가 저장될 폴더
    :param split_ratio: 학습:검증 데이터 비율
    """
    for class_name in os.listdir(input_folder):  # 각 클래스 ('real', 'fake') 순회
        class_path = os.path.join(input_folder, class_name)  # 클래스 폴더 경로
        train_class_folder = os.path.join(train_folder, class_name)  # 학습 데이터 폴더
        val_class_folder = os.path.join(val_folder, class_name)  # 검증 데이터 폴더

        os.makedirs(train_class_folder, exist_ok=True)  # 폴더 생성
        os.makedirs(val_class_folder, exist_ok=True)

        files = os.listdir(class_path)  # 클래스 내 파일 리스트
        random.shuffle(files)  # 파일을 랜덤하게 섞기

        split_index = int(len(files) * split_ratio)  # 분할 인덱스 계산
        train_files = files[:split_index]  # 학습 데이터
        val_files = files[split_index:]  # 검증 데이터

        for file in train_files:  # 학습 데이터 복사
            shutil.copy(os.path.join(class_path, file), train_class_folder)

        for file in val_files:  # 검증 데이터 복사
            shutil.copy(os.path.join(class_path, file), val_class_folder)

# ------------------------------
# 3. 모델 정의 및 학습
# ------------------------------
def train_model(model, train_loader, criterion, optimizer, num_epochs):
    """
    모델 학습 루프를 수행합니다.
    :param model: 학습할 모델
    :param train_loader: 학습 데이터 로더
    :param criterion: 손실 함수
    :param optimizer: 최적화 알고리즘
    :param num_epochs: 학습 반복 횟수
    """
    model.train()  # 모델을 학습 모드로 설정
    for epoch in range(num_epochs):  # 각 에폭 반복
        running_loss = 0.0  # 에폭 손실 초기화
        for images, labels in train_loader:  # 배치 데이터 가져오기
            optimizer.zero_grad()  # 기존 그래디언트 초기화
            outputs = model(images)  # 모델 예측
            loss = criterion(outputs, labels)  # 손실 계산
            loss.backward()  # 그래디언트 계산
            optimizer.step()  # 모델 파라미터 업데이트
            running_loss += loss.item() * images.size(0)  # 배치 손실 합산

        epoch_loss = running_loss / len(train_loader.dataset)  # 평균 손실 계산
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}")  # 에폭 결과 출력

def validate_model(model, val_loader, criterion):
    """
    모델 검증 루프를 수행합니다.
    :param model: 학습된 모델
    :param val_loader: 검증 데이터 로더
    :param criterion: 손실 함수
    """
    model.eval()  # 모델을 평가 모드로 설정
    running_loss = 0.0  # 검증 손실 초기화
    correct = 0  # 정확히 예측한 개수
    with torch.no_grad():  # 검증 시에는 그래디언트 계산하지 않음
        for images, labels in val_loader:  # 배치 데이터 가져오기
            outputs = model(images)  # 모델 예측
            loss = criterion(outputs, labels)  # 손실 계산
            running_loss += loss.item() * images.size(0)  # 배치 손실 합산
            _, preds = torch.max(outputs, 1)  # 예측 결과
            correct += (preds == labels).sum().item()  # 정확한 예측 개수 합산

    val_loss = running_loss / len(val_loader.dataset)  # 평균 검증 손실 계산
    accuracy = correct / len(val_loader.dataset)  # 정확도 계산
    print(f"Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}")  # 결과 출력

# ------------------------------
# 4. 실행
# ------------------------------
# 데이터 준비
frames_folder = 'processed_frames'  # 프레임 저장 폴더 경로
extract_frames_from_videos(data_folder, frames_folder, frame_count, image_size)  # 프레임 추출
split_dataset(frames_folder, train_folder, val_folder, split_ratio)  # 학습/검증 데이터 분할

# 데이터셋 로드
transform = transforms.Compose([
    transforms.Resize(image_size),  # 이미지 크기 조정
    transforms.ToTensor(),  # 텐서 변환
])

train_data = datasets.ImageFolder(train_folder, transform=transform)  # 학습 데이터셋
val_data = datasets.ImageFolder(val_folder, transform=transform)  # 검증 데이터셋

train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)  # 학습 데이터 로더
val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)  # 검증 데이터 로더

# 모델 정의
model = models.resnet18(pretrained=True)  # 사전 학습된 ResNet18 모델 불러오기
model.fc = nn.Linear(model.fc.in_features, len(train_data.classes))  # 출력 레이어 수정 (클래스 수에 맞게)

criterion = nn.CrossEntropyLoss()  # 손실 함수 정의
optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # 옵티마이저 정의

# 학습 및 검증
train_model(model, train_loader, criterion, optimizer, num_epochs)  # 모델 학습
validate_model(model, val_loader, criterion)  # 모델 검증
