```
from google.colab import drive
import os
import cv2
import random
import shutil
import zipfile
import logging
import time
```

# Google Drive를 마운트하여 파일에 액세스합니다.
drive.mount('/content/drive')

# ------------------------------
# 1. 설정
# ------------------------------
```
zip_file_path = '/content/drive/MyDrive/dfdc_train_part_00.zip'  # 압축 파일 경로
data_folder = 'deepfake_dataset'  # 압축 해제 후 데이터 폴더
frames_folder = 'processed_frames'  # 추출된 프레임 저장 폴더
train_folder = 'dataset/train'  # 학습 데이터 저장 폴더
val_folder = 'dataset/val'  # 검증 데이터 저장 폴더
frame_count = 5  # 각 영상에서 추출할 프레임 수를 5로 설정 (기존: 10)
split_ratio = 0.8  # 학습:검증 데이터 비율
image_size = (64, 64)  # 리사이즈 크기
```
# ------------------------------
# 2.데이터 준비 함수 부분
# ------------------------------
# 로그 설정
```
# 로깅 설정: 로그 파일에 기록하면서, 시간, 로그 레벨, 메시지를 포함한 형식 지정
logging.basicConfig(
    filename='program.log', 
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s'
)

def log_and_print(message):
    """로그 파일에 기록하면서 동시에 화면에 출력"""
    logging.info(message)
    print(message)
def extract_frames_from_videos(data_folder, output_folder, frame_count, image_size):
    """
    주어진 데이터 폴더 내 비디오에서 프레임을 추출하여 출력 폴더에 저장

    Parameters:
        data_folder (str): 비디오 데이터가 포함된 폴더 경로
        output_folder (str): 추출된 프레임을 저장할 폴더 경로
        frame_count (int): 비디오에서 추출할 프레임 수
        image_size (tuple): 프레임의 리사이즈 크기 (너비, 높이)
    """
    os.makedirs(output_folder, exist_ok=True)
    for class_name in os.listdir(data_folder):  # 'real', 'fake' 순회
        class_path = os.path.join(data_folder, class_name)  # 각 클래스 폴더 경로
        output_class_folder = os.path.join(output_folder, class_name)  # 출력 폴더 경로
        os.makedirs(output_class_folder, exist_ok=True)   # 출력 클래스 폴더 생성

        start_time = time.time()   # 처리 시작 시간 기록
        log_and_print(f"Processing videos in class '{class_name}'...")
        video_count = 0

        for video_file in os.listdir(class_path):  # 클래스 폴더 내 비디오 파일 순회
            video_path = os.path.join(class_path, video_file)  # 비디오 파일 경로
            cap = cv2.VideoCapture(video_path)  # 비디오 캡처 객체 생성
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # 비디오의 총 프레임 수 계산
            # 프레임 간격(interval)을 기존의 두 배로 늘려서 처리
            interval = max(total_frames // (frame_count * 2), 1)  # 간격을 늘려서 프레임 추출 수를 줄임

            frame_number = 0
            saved_frames = 0
            video_name = os.path.splitext(video_file)[0]

            while cap.isOpened() and saved_frames < frame_count:
                ret, frame = cap.read()
                if not ret:  # 비디오에서 프레임 읽기 실패 시 처리
                    break
                if frame_number % interval == 0:  # 간격에 맞는 프레임 저장
                    frame_filename = os.path.join(output_class_folder, f"{video_name}_frame_{saved_frames}.jpg")
                    resized_frame = cv2.resize(frame, image_size) # 프레임 리사이즈
                    cv2.imwrite(frame_filename, resized_frame) # 리사이즈된 프레임 저장
                    saved_frames += 1 # 저장된 프레임 수 증가
                frame_number += 1 # 프레임 번호 증가

            cap.release() # 비디오 캡처 객체 해제
            video_count += 1 # 처리한 비디오 수 증가

        end_time = time.time() # 처리 종료 시간 기록
        log_and_print(f"Completed processing {video_count} videos in class '{class_name}' in {end_time - start_time:.2f} seconds.")

def split_dataset(input_folder, train_folder, val_folder, split_ratio):
    """
    데이터를 학습 및 검증 세트로 분할

    Parameters:
        input_folder (str): 입력 데이터 폴더 경로
        train_folder (str): 학습 데이터 저장 폴더 경로
        val_folder (str): 검증 데이터 저장 폴더 경로
        split_ratio (float): 학습 데이터 비율 (0.0 ~ 1.0)
    """
    for class_name in os.listdir(input_folder):  # 클래스 폴더 순회
        class_path = os.path.join(input_folder, class_name)  # 클래스 폴더 경로
        train_class_folder = os.path.join(train_folder, class_name)  # 학습 데이터 폴더 경로
        val_class_folder = os.path.join(val_folder, class_name)  # 검증 데이터 폴더 경로

        os.makedirs(train_class_folder, exist_ok=True)  # 학습 데이터 폴더 생성
        os.makedirs(val_class_folder, exist_ok=True)  # 검증 데이터 폴더 생성

        files = os.listdir(class_path)  # 클래스 폴더 내 모든 파일 가져오기
        random.shuffle(files)  # 파일 순서를 무작위로 섞기

        split_index = int(len(files) * split_ratio)  # 학습 데이터와 검증 데이터 분할 인덱스 계산
        train_files = files[:split_index]  # 학습 데이터 파일 목록
        val_files = files[split_index:]  # 검증 데이터 파일 목록

        start_time = time.time() # 분할 시작 시간 기록
        log_and_print(f"Splitting dataset for class '{class_name}' into train and validation sets...")

        for file in train_files: # 학습 데이터로 복사
            shutil.copy(os.path.join(class_path, file), train_class_folder)

        for file in val_files:  # 검증 데이터로 복사
            shutil.copy(os.path.join(class_path, file), val_class_folder)

        end_time = time.time() # 분할 종료 시간 기록
        log_and_print(f"Completed splitting dataset for class '{class_name}' in {end_time - start_time:.2f} seconds.")
```

# ------------------------------
#3. 압축 해제 및 데이터 준비 실행
# ------------------------------
```
log_and_print("Starting dataset preparation...")

# 압축 해제
log_and_print("Extracting dataset from zip file...")
start_time = time.time()
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(data_folder)
end_time = time.time()
log_and_print(f"Dataset extracted in {end_time - start_time:.2f} seconds.")

# 프레임 추출
log_and_print("Extracting frames from videos...")
extract_frames_from_videos(data_folder, frames_folder, frame_count, image_size)

# 데이터셋 분할
log_and_print("Splitting frames into train and validation sets...")
split_dataset(frames_folder, train_folder, val_folder, split_ratio)

log_and_print("Dataset preparation completed!")
```



```
import torch
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
import torch.nn as nn
import torch.optim as optim
```
# ------------------------------
# 1. 설정
# ------------------------------
```
batch_size = 16  # 배치 크기
num_epochs = 10  # 학습 에폭 수
learning_rate = 0.001  # 학습률
image_size = (64, 64)  # 이미지 크기
```

# ------------------------------
# 2. 데이터 로드
# ------------------------------
```
transform = transforms.Compose([
    transforms.Resize(image_size),
    transforms.ToTensor(),
])

train_data = datasets.ImageFolder(train_folder, transform=transform)
val_data = datasets.ImageFolder(val_folder, transform=transform)

train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)
```
# ------------------------------
# 3. 모델 정의
# ------------------------------
```
model = models.resnet18(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, len(train_data.classes))

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
```
# ------------------------------
# 4. 학습 함수
# ------------------------------
```
def train_model(model, train_loader, criterion, optimizer, num_epochs):
    model.train()
    for epoch in range(num_epochs):
        running_loss = 0.0
        for images, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item() * images.size(0)

        epoch_loss = running_loss / len(train_loader.dataset)
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}")
```
# ------------------------------
# 5. 검증 함수
# ------------------------------
```
def validate_model(model, val_loader, criterion):
    model.eval()
    running_loss = 0.0
    correct = 0
    with torch.no_grad():
        for images, labels in val_loader:
            outputs = model(images)
            loss = criterion(outputs, labels)
            running_loss += loss.item() * images.size(0)
            _, preds = torch.max(outputs, 1)
            correct += (preds == labels).sum().item()

    val_loss = running_loss / len(val_loader.dataset)
    accuracy = correct / len(val_loader.dataset)
    print(f"Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}")
```
# ------------------------------
# 6. 학습 및 검증 실행
# ------------------------------
```
train_model(model, train_loader, criterion, optimizer, num_epochs)
validate_model(model, val_loader, criterion)
```
