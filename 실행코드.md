```
from google.colab import drive
import os
import cv2
import random
import shutil
import zipfile
import logging
import time
import torch
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
import torch.nn as nn
import torch.optim as optim
```
# Google Drive를 마운트하여 파일에 액세스합니다.
```
drive.mount('/content/drive')
```
# ------------------------------
# 1. 데이터 준비 설정
# ------------------------------
```
zip_file_path = '/content/drive/MyDrive/dfdc_train_part_00.zip'
data_folder = 'deepfake_dataset'
frames_folder = 'processed_frames'
train_folder = '/content/drive/MyDrive/deepfake_dataset/train'
val_folder = '/content/drive/MyDrive/deepfake_dataset/val'
frame_count = 5
split_ratio = 0.8
image_size = (64, 64)
```
# 로그 설정
```
logging.basicConfig(
    filename='program.log',  # 로그 파일을 program.log로 설정
    level=logging.INFO,  # 로그 레벨을 INFO로 설정
    format='%(asctime)s - %(levelname)s - %(message)s' # 로그 형식: 시간, 레벨, 메시지
)

# log_and_print() 함수 정의: 메시지를 로그에 기록하고 동시에 출력
def log_and_print(message):
    logging.info(message)
    print(message)

# extract_frames_from_videos() 함수 정의: 비디오 파일에서 프레임을 추출하고 저장
def extract_frames_from_videos(data_folder, output_folder, frame_count, image_size):
    os.makedirs(output_folder, exist_ok=True)
    for class_name in os.listdir(data_folder): # 데이터 폴더 내의 각 클래스 디렉토리마다 작업 수행
        class_path = os.path.join(data_folder, class_name)  # 클래스별 비디오 파일들이 있는 경로
        output_class_folder = os.path.join(output_folder, class_name)  # 클래스별로 프레임을 저장할 폴더 경로
        os.makedirs(output_class_folder, exist_ok=True)  # 클래스 폴더가 없으면 생성

        start_time = time.time()  # 시작 시간 기록
        log_and_print(f"Processing videos in class '{class_name}'...")
        video_count = 0  # 비디오 파일 개수를 셀 변수

        # 클래스 내의 각 비디오 파일에 대해 프레임 추출
        for video_file in os.listdir(class_path):
            video_path = os.path.join(class_path, video_file)
            cap = cv2.VideoCapture(video_path)  # OpenCV로 비디오 파일 열기
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # 비디오의 총 프레임 수
            interval = max(total_frames // (frame_count * 2), 1)  # 간격 계산 (프레임 수가 frame_count의 2배 이상이 되도록)

            frame_number = 0
            saved_frames = 0
            video_name = os.path.splitext(video_file)[0]

            while cap.isOpened() and saved_frames < frame_count:
                ret, frame = cap.read()
                if not ret:
                    break
                if frame_number % interval == 0:  # 지정된 간격으로만 프레임 저장
                    frame_filename = os.path.join(output_class_folder, f"{video_name}_frame_{saved_frames}.jpg")  # 프레임 파일명
                    resized_frame = cv2.resize(frame, image_size)  # 지정된 크기로 프레임 리사이즈
                    cv2.imwrite(frame_filename, resized_frame)  # 리사이즈된 프레임 저장
                    saved_frames += 1  # 저장한 프레임 수 증가
                frame_number += 1  # 프레임 번호 증가

            cap.release()  # 비디오 캡처 객체 해제
            video_count += 1  # 비디오 파일 처리 완료 카운트 증가

        end_time = time.time()
        log_and_print(f"Completed processing {video_count} videos in class '{class_name}' in {end_time - start_time:.2f} seconds.")

# split_dataset() 함수 정의: 데이터셋을 학습용과 검증용으로 나누는 함수
def split_dataset(input_folder, train_folder, val_folder, split_ratio):
    # 입력 폴더의 각 클래스 디렉토리마다 작업 수행
    for class_name in os.listdir(input_folder):
        class_path = os.path.join(input_folder, class_name)
        train_class_folder = os.path.join(train_folder, class_name)
        val_class_folder = os.path.join(val_folder, class_name)

        os.makedirs(train_class_folder, exist_ok=True)
        os.makedirs(val_class_folder, exist_ok=True)

        files = os.listdir(class_path)
        random.shuffle(files)

        split_index = int(len(files) * split_ratio)
        train_files = files[:split_index]
        val_files = files[split_index:]

        start_time = time.time()
        log_and_print(f"Splitting dataset for class '{class_name}' into train and validation sets...")

        # 학습용 파일을 학습용 폴더에 복사
        for file in train_files:
            shutil.copy(os.path.join(class_path, file), train_class_folder)

        # 검증용 파일을 검증용 폴더에 복사
        for file in val_files:
            shutil.copy(os.path.join(class_path, file), val_class_folder)

        end_time = time.time()
        log_and_print(f"Completed splitting dataset for class '{class_name}' in {end_time - start_time:.2f} seconds.")
```
# ------------------------------
# 2. 데이터 준비 실행
# ------------------------------
```
log_and_print("Starting dataset preparation...")
# 압축 해제
log_and_print("Extracting dataset from zip file...")
start_time = time.time()
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(data_folder)
end_time = time.time()
log_and_print(f"Dataset extracted in {end_time - start_time:.2f} seconds.")

# 프레임 추출
log_and_print("Extracting frames from videos...")
extract_frames_from_videos(data_folder, frames_folder, frame_count, image_size)

# 데이터셋 분할
log_and_print("Splitting frames into train and validation sets...")
split_dataset(frames_folder, train_folder, val_folder, split_ratio)
```
# ------------------------------
# 3. 모델 학습 및 검증
# ------------------------------
```
# 학습 파라미터 설정
batch_size = 16
num_epochs = 10
learning_rate = 0.001

# GPU 사용 여부 체크
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# 데이터 로드 및 확인
transform = transforms.Compose([transforms.Resize(image_size), transforms.ToTensor()])
train_dataset = datasets.ImageFolder(train_folder, transform=transform)
val_dataset = datasets.ImageFolder(val_folder, transform=transform)

# DataLoader 설정
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)

# ResNet18 모델 설정
model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
model.fc = nn.Linear(model.fc.in_features, len(train_dataset.classes))
model = model.to(device)

# 손실 함수 및 옵티마이저 설정
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# 학습 함수
def train_model(model, train_loader, criterion, optimizer, num_epochs, device):
    model.train()
    for epoch in range(num_epochs):
        running_loss = 0.0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item() * images.size(0)

        epoch_loss = running_loss / len(train_loader.dataset)
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}")

# 검증 함수
def validate_model(model, val_loader, criterion, device):
    model.eval()
    running_loss = 0.0
    correct = 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            running_loss += loss.item() * images.size(0)
            _, preds = torch.max(outputs, 1)
            correct += (preds == labels).sum().item()

    val_loss = running_loss / len(val_loader.dataset)
    accuracy = correct / len(val_loader.dataset)
    print(f"Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}")

# 모델 학습 및 검증
train_model(model, train_loader, criterion, optimizer, num_epochs, device)
validate_model(model, val_loader, criterion, device)

```
